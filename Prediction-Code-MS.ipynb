{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "\n",
    "This code and analyses were produced Jason Anastasopoulos (j.andronici@gmail.com)\n",
    "and Anthony Bertelli for the paper \"Understanding Delegation Through Machine Learning: A Method and Application to the EU\" published in the *American Political Science Review*: \n",
    "\n",
    "\n",
    "https://www.cambridge.org/core/journals/american-political-science-review/article/understanding-delegation-through-machine-learning-a-method-and-application-to-the-european-union/1724F3ECFA1F0AABE3C7F8DA5C5D521B\n",
    "\n",
    "Here we make predictions on parsed EU Directives and Regulations for the Member State\n",
    "\n",
    "- Citation:\n",
    "*Anastasopoulos, L. Jason, and Anthony M. Bertelli. \"Understanding delegation through machine learning: A method and application to the European Union.\" American Political Science Review 114, no. 1 (2020): 291-301.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing directive data for prediction\n",
    "\n",
    "Parsed directives and regulations are saved on a local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(pacman)\n",
    "\n",
    "\n",
    "# This loads and installs the packages you need at once\n",
    "pacman::p_load(tm,SnowballC,foreign,plyr,twitteR,slam,foreign,wordcloud,LiblineaR,e1071, topicmodels,readr,\n",
    "              caret,dplyr,xgboost,quanteda)\n",
    "\n",
    "# Load the regulation data\n",
    "directive_provisions_regs = \"/Users/jason/Desktop/Provisions/regulation-articles.csv\"\n",
    "newprovisiondata_regs<-read.csv(directive_provisions_regs)\n",
    "\n",
    "# Load the directive data\n",
    "\n",
    "directive_provisions_dirs = \"/Users/jason/Desktop/Provisions/directive-articles.csv\"\n",
    "newprovisiondata_dirs<-read.csv(directive_provisions_dirs)\n",
    "\n",
    "#[1] \"celex\"    \"fileyear\" \"day\"      \"month\"    \"year\"     \"article\" \n",
    "\n",
    "newprovisiondata_dirs<-newprovisiondata_dirs[,1:6]\n",
    "# Restrict from 1960 onward\n",
    "newprovisiondata_dirs<-newprovisiondata_dirs[as.numeric(as.character(newprovisiondata_dirs$fileyear))>1960,]\n",
    "newprovisiondata_dirs[,2]<-as.numeric(as.character(newprovisiondata_dirs[,2]))\n",
    "newprovisiondata_dirs[,3]<-as.numeric(as.character(newprovisiondata_dirs[,3]))\n",
    "newprovisiondata_dirs[,4]<-as.numeric(as.character(newprovisiondata_dirs[,4]))\n",
    "newprovisiondata_dirs[,5]<-as.numeric(as.character(newprovisiondata_dirs[,5]))\n",
    "\n",
    "# Combine these into one mega data frame\n",
    "\n",
    "newprovisiondata<-bind_rows(newprovisiondata_regs,newprovisiondata_dirs)\n",
    "\n",
    "# Save the year, month and celex, but get rid of the text\n",
    "newprovision.year = newprovisiondata$fileyear\n",
    "newprovision.celex = newprovisiondata$celex\n",
    "newprovisiondata.month = newprovisiondata$month\n",
    "\n",
    "rawtext = newprovisiondata$article\n",
    "\n",
    "## Process the text data\n",
    "# Preprocess the text\n",
    "\n",
    "# Now we have to put the training data and classification data into one matrix\n",
    "\n",
    "cleancorpus.predict<-corpus(rawtext)\n",
    "\n",
    "token.dirty  = tokens(cleancorpus.predict,ngrams = 1:2)\n",
    "token.clean = tokens_select(token.dirty, \n",
    "                            c(\"/\",\"@\", \"\\\\|\",\"#\",\"http\",\"https\" ,\".com\",\"$\", \" g \"),\n",
    "                            selection =\"remove\")\n",
    "\n",
    "\n",
    "dtm.predict <- dfm(token.clean, remove = stopwords(\"english\"), \n",
    "                   remove_punct = TRUE,stem = TRUE)\n",
    "\n",
    "# Remove the big files for memory concerns\n",
    "rm(newprovisiondata_regs,newprovisiondata_dirs,provisiontext.predict,cleancorpus.predict,newprovisiondata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for constraint classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.delegation.data = data.frame(newprovision.celex,newprovisiondata.month,newprovision.year)\n",
    "\n",
    "classifier.list = list.files(\"~/Dropbox/Research/Papers/Delegation-ML-Project/Dataverse Files copy/Pipeline/Trained_Classifiers_MS\")\n",
    "\n",
    "science = c() # We're going to fill this with file paths.\n",
    "\n",
    "for(i in 1:length(classifier.list)){\n",
    "  science[i] = paste(\"~/Dropbox/Research/Papers/Delegation-ML-Project/Dataverse Files copy/Pipeline/Trained_Classifiers_MS/\",\n",
    "                     classifier.list[i],sep = \"\")\n",
    "}\n",
    "\n",
    "colnames.classifiers = c()\n",
    "\n",
    "# Generate predictions for each of the constraint classifiers, save the predictions in a big ass file\n",
    "for(i in 1:length(science)){\n",
    "  load(science[i])\n",
    "  print(science[i])\n",
    "\n",
    "  # First step is to match the columns to subset\n",
    "  colnames<-colnames(trainX)\n",
    "  fullnames<-dtm.predict@Dimnames$features\n",
    "  indexno<-c()\n",
    "\n",
    "  for(j in 1:length(colnames)){\n",
    "    tempname = colnames[j]\n",
    "    indexnum = which(tempname == fullnames)\n",
    "    indexno = c(indexno, indexnum)\n",
    "  }\n",
    "\n",
    "\n",
    "  dtm_mat_class<-dtm.predict[,indexno]\n",
    "\n",
    "  # Make predictions\n",
    "  constraint.probs <- as.vector(predict(xgb1,dtm_mat_class))\n",
    "  constraint.predictions <- ifelse(constraint.probs > 0.5,1,0)\n",
    "  \n",
    "  final.delegation.data = data.frame(final.delegation.data, constraint.probs,constraint.predictions)\n",
    "  colnames.classifiers = c(colnames.classifiers,\n",
    "                           paste(constrainttype,\".probs\", sep = \"\"), \n",
    "                          paste(constrainttype,\".preds\", sep =\"\"))\n",
    "  #rm(science[i])\n",
    "}\n",
    "\n",
    "names(final.delegation.data)[4:dim(final.delegation.data)[2]]<-colnames.classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for delegation classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "################################ Delegation Classifier  ##################################################################\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "\n",
    "load(\"~/Dropbox/Research/Papers/Delegation-ML-Project/Dataverse Files copy/Pipeline/Trained_Classifiers_MS/delegation-ms.RData\")\n",
    "\n",
    "# First step is to match the columns to subset\n",
    "colnames<-colnames(trainX)\n",
    "fullnames<-dtm.predict@Dimnames$features\n",
    "indexno<-c()\n",
    "\n",
    "for(j in 1:length(colnames)){\n",
    "  tempname = colnames[j]\n",
    "  indexnum = which(tempname == fullnames)\n",
    "  indexno = c(indexno, indexnum)\n",
    "}\n",
    "\n",
    "\n",
    "dtm_mat_class<-dtm.predict[,indexno]\n",
    "\n",
    "# Make predictions\n",
    "delegation.probs <- as.vector(predict(xgb1,dtm_mat_class))\n",
    "delegation.predictions <- ifelse(delegation.probs > 0.5,1,0)\n",
    "\n",
    "\n",
    "final.delegation.data = data.frame(final.delegation.data, delegation.probs,delegation.predictions,rawtext)\n",
    "\n",
    "\n",
    "write.csv(final.delegation.data,\n",
    "\"~/Dropbox/Research/Papers/Delegation-ML-Project/Dataverse Files copy/Pipeline/Disaggregated-Predictions/disaggregated-ms-predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
