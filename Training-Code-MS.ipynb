{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "\n",
    "This code and analyses were produced Jason Anastasopoulos (j.andronici@gmail.com)\n",
    "and Anthony Bertelli for the paper \"Understanding Delegation Through Machine Learning: A Method and Application to the EU\" published in the *American Political Science Review*: \n",
    "\n",
    "\n",
    "https://www.cambridge.org/core/journals/american-political-science-review/article/understanding-delegation-through-machine-learning-a-method-and-application-to-the-european-union/1724F3ECFA1F0AABE3C7F8DA5C5D521B\n",
    "\n",
    "\n",
    "Here we train a series of gradient boosted tree classifiers on the hand coded delegation and constraint data,\n",
    "apply to classifier to the provisions, and calculate delegation and constraint ratios \n",
    "Each of the trained classifiers are saved in a .RData file\n",
    "\n",
    "- Citation:\n",
    "*Anastasopoulos, L. Jason, and Anthony M. Bertelli. \"Understanding delegation through machine learning: A method and application to the European Union.\" American Political Science Review 114, no. 1 (2020): 291-301.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier training and performance.\n",
    "- member state classifier.\n",
    "- Multiple classifiers for each constraint.\n",
    "- Single delegation classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin with member state classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(pacman)\n",
    "\n",
    "\n",
    "# This loads and installs the packages you need at once\n",
    "pacman::p_load(tm,SnowballC,foreign,plyr,twitteR,slam,foreign,wordcloud,LiblineaR,e1071, topicmodels,readr,\n",
    "               monkeylearn, EBglmnet, bayesreg, ggplot2,randomForest,\n",
    "               glmnet, monomvn, caret, rpart, xgboost, boot,dplyr, ranger,\n",
    "               xgboost,quanteda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing and creation of document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed Franchino data.\n",
    "\n",
    "data = \"~/Dropbox/Research/Papers/Delegation-ML-Project/Dataverse Files copy/Training Data/Training_Data_MS.csv\"\n",
    "\n",
    "textdata<-read.csv(data)\n",
    "\n",
    "provision.text = textdata$Text\n",
    "\n",
    "# Let's create two categories of constraints\n",
    "# Constraints to members states\n",
    "\n",
    "#[10] \"MS.Time.Limit\"                    \"MS.Reporting.Requirements\"        \"MS.Consultation.Requirements\"    \n",
    "#[13] \"MS.Appeals.Procedures\"            \"MS.Executive.Action.Required\"     \"MS.Legislative.Action.Required\"  \n",
    "#[16] \"MS.Spending.Limits\"               \"MS.Executive.Action.Possible\"     \"MS.Exemptions\" \n",
    "\n",
    "# Need to train a classifier for each of these categories of constraints and then we need to report\n",
    "# the statistics for each of these\n",
    "\n",
    "constraints.member<-textdata[,9:20]\n",
    "delegation.member<-textdata$Lable\n",
    "\n",
    "\n",
    "data.constraints.MS<-data.frame(provision.text,constraints.member)\n",
    "data.delegation.MS<-data.frame(provision.text,delegation.member)\n",
    "\n",
    "# Use regular expressions to clean up some elements of the documents\n",
    "cleandocs<-c()\n",
    "\n",
    "\n",
    "# Preprocess the text using quanteda\n",
    "\n",
    "# Now we have to put the training data and classification data into one matrix\n",
    "\n",
    "provisiontext<-sapply(textdata$Text,as.character)\n",
    "\n",
    "provisiontext = corpus(provisiontext) # Create a corpus object\n",
    "\n",
    "token.dirty  = tokens(provisiontext,ngrams = 1:2)\n",
    "token.clean = tokens_select(token.dirty, \n",
    "                            c(\"/\",\"@\", \"\\\\|\",\"#\",\"http\",\"https\" ,\".com\",\"$\", \" g \"),\n",
    "                            selection =\"remove\")\n",
    "                            \n",
    "dtm.new = dfm(token.clean, remove = stopwords(\"english\"), \n",
    "              remove_punct = TRUE,stem = TRUE)\n",
    "\n",
    "dtm.new  = dfm_trim(dtm.new,sparsity=.99)\n",
    "\n",
    "data.constraints.MS.new<-data.constraints.MS\n",
    "data.delegation.MS.new<-data.delegation.MS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Member state constraint classifiers\n",
    "\n",
    "Next we estimate a series of classifiers for each constraint included in the Franchino data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "##################################    Classifier Training Performance Constraint ###########################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "\n",
    "# We have to train 12 different classifiers for constraint, safe the classifiers as objects, report performance of the\n",
    "# classifiers and word importance plots \n",
    "\n",
    "#\"MS.Rulemaking.Requirements\"      \n",
    "#[10] \"MS.Time.Limit\"                    \"MS.Reporting.Requirements\"        \"MS.Consultation.Requirements\"    \n",
    "#[13] \"MS.Appeals.Procedures\"            \"MS.Executive.Action.Required\"     \"MS.Legislative.Action.Required\"  \n",
    "#[16] \"MS.Spending.Limits\"               \"MS.Executive.Action.Possible\"     \"MS.Exemptions\"                   \n",
    "#[19] \"MS.Public.Hearings\"               \"MS.Legislative.Action.Possible\"\n",
    "\n",
    "\n",
    "# Constraint names\n",
    "#constraint.names.upper = names(data.constraints.MS.new[,2:13])\n",
    "#constraint.names.lower = tolower(names(data.constraints.MS.new[,2:13]))\n",
    "#constraint.names.mat = data.frame(rep(0,dim(data.constraints.MS.new)[1]))\n",
    "\n",
    "#[1] \"ms.rulemaking.requirements\"     \"ms.time.limit\"                  \"ms.reporting.requirements\"     \n",
    "#[4] \"ms.consultation.requirements\"   \"ms.appeals.procedures\"          \"ms.executive.action.required\"  \n",
    "#[7] \"ms.legislative.action.required\" \"ms.spending.limits\"             \"ms.executive.action.possible\"  \n",
    "#[10] \"ms.exemptions\"                  \"ms.public.hearings\"             \"ms.legislative.action.possible\"\n",
    "\n",
    "# List of the constraints, delegation ratio is going to have to have a denominator of 6\n",
    "ms.rulemaking.requirements<- data.constraints.MS.new$MS.Rulemaking.Requirements\n",
    "ms.rulemaking.requirements<- ifelse(as.numeric(ms.rulemaking.requirements) >= 2, 1,0)\n",
    "\n",
    "ms.time.limit<-data.constraints.MS.new$MS.Time.Limit\n",
    "ms.time.limit<-ifelse(ms.time.limit >= 1, 1,0)\n",
    "\n",
    "ms.reporting.requirements<-data.constraints.MS.new$MS.Reporting.Requirements\n",
    "ms.reporting.requirements<-ifelse(ms.reporting.requirements >= 1, 1,0)\n",
    "\n",
    "ms.consultation.requirements<-data.constraints.MS.new$MS.Consultation.Requirements\n",
    "ms.consultation.requirements<-ifelse(ms.consultation.requirements >= 1, 1,0)\n",
    "\n",
    "ms.appeals.procedures<-data.constraints.MS.new$MS.Appeals.Procedures\n",
    "ms.appeals.procedures<-ifelse(ms.appeals.procedures >= 1, 1,0)\n",
    "\n",
    "ms.executive.action.required<-data.constraints.MS.new$MS.Executive.Action.Required\n",
    "ms.executive.action.required<-ifelse(ms.executive.action.required >= 1, 1,0) # Unusable\n",
    "\n",
    "ms.legislative.action.required<-data.constraints.MS.new$MS.Legislative.Action.Required\n",
    "ms.legislative.action.required<-ifelse(ms.legislative.action.required >= 1, 1,0) # Unusable\n",
    "\n",
    "ms.spending.limits<-data.constraints.MS.new$MS.Spending.Limits\n",
    "ms.spending.limits<-ifelse(ms.spending.limits >= 1, 1,0)\n",
    "\n",
    "ms.executive.action.possible<-data.constraints.MS.new$MS.Executive.Action.Possible\n",
    "ms.executive.action.possible<-ifelse(ms.executive.action.possible >= 1, 1,0) # Unusable\n",
    "\n",
    "ms.exemptions<-data.constraints.MS.new$MS.Exemptions\n",
    "ms.exemptions<-ifelse(ms.exemptions >= 1, 1,0) # Unusable\n",
    "\n",
    "ms.public.hearings<-data.constraints.MS.new$MS.Public.Hearings\n",
    "ms.public.hearings<-ifelse(ms.public.hearings >= 1, 1,0) # Unusable\n",
    "\n",
    "ms.legislative.action.possible<-data.constraints.MS.new$MS.Legislative.Action.Possible\n",
    "ms.legislative.action.possible<-ifelse(ms.legislative.action.possible >= 1, 1,0) #Unusable\n",
    "\n",
    "# Let's put all of the constraints into a final matrix\n",
    "constraint.label.mat = data.frame(\n",
    "  ms.rulemaking.requirements,\n",
    "  ms.time.limit,\n",
    "  ms.reporting.requirements,\n",
    "  ms.consultation.requirements,\n",
    "  ms.appeals.procedures,\n",
    "  ms.executive.action.required,\n",
    "  ms.spending.limits,\n",
    "  ms.executive.action.possible\n",
    ")\n",
    "\n",
    "# Now we have to train 8 classifiers\n",
    "classifiers = c()\n",
    "constraint.performance.table = data.frame(c(0),c(0), c(0), c(0), c(0),c(0))\n",
    "names(constraint.performance.table) = c(\"Constraint Type\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"F1\",\"Precision\")\n",
    "classifiernames = c(\"xgb1\",\"xgb2\",\"xgb3\",\"xgb4\",\"xgb5\",\"xgb6\")\n",
    "\n",
    "# Start loop here\n",
    "for(i in 1:dim(constraint.label.mat)[2]){ \n",
    "  set.seed(42616)\n",
    "  dtm_mat<-as.matrix(dtm.new)\n",
    "  mllabel = data.frame(constraint.label.mat[,i],dtm_mat)\n",
    "  train=sample(1:dim(mllabel)[1],\n",
    "               dim(mllabel)[1]*0.70)\n",
    "  dtm_mat<-as.matrix(dtm.new)\n",
    "  trainX = dtm_mat[train,]\n",
    "  testX = dtm_mat[-train,]\n",
    "  trainY = constraint.label.mat[,i][train]\n",
    "  testY = constraint.label.mat[,i][-train]\n",
    "\n",
    "  traindata<-data.frame(trainY,trainX)\n",
    "  testdata<-data.frame(testY,testX)\n",
    "\n",
    "  traindata.b <- xgb.DMatrix(data = trainX,label = trainY) \n",
    "  testdata.b  <- xgb.DMatrix(data = testX,label=testY)\n",
    "\n",
    "  pospredweight = as.vector(table(trainY)[1])/as.vector(table(trainY)[2])\n",
    "\n",
    "  set.seed(100)\n",
    "\n",
    "  # Parameter tuning\n",
    "  # these are default parameters\n",
    "  params <- list(booster = \"gbtree\", objective = \"binary:logistic\", \n",
    "               eta=0.3, gamma=0, max_depth=6, min_child_weight=1, \n",
    "               subsample=1, colsample_bytree=1)\n",
    "\n",
    "  xgbcv<- xgb.cv( params = params, data = traindata.b,\n",
    "                 nrounds = 200, nfold = 5, showsd = T, \n",
    "                 stratified = T, early.stopping.rounds = 20, print.every_n = 10,\n",
    "                 maximize = F,\n",
    "                 scale_pos_weight = pospredweight)\n",
    "  \n",
    "  ## Plot train and test error\n",
    "  test.error = xgbcv$evaluation_log[,4]\n",
    "  train.error = xgbcv$evaluation_log[,2]\n",
    "  \n",
    "  # Which number of iterations has the lowest training error?\n",
    "  best.iter = which(xgbcv$evaluation_log$test_error_mean ==  min(xgbcv$evaluation_log$test_error_mean))\n",
    "  best.iter = best.iter[1]\n",
    "\n",
    "  #first default - model training\n",
    "      xgb1 <- xgb.train(params = params, data = traindata.b, \n",
    "                  nrounds = best.iter, \n",
    "                  watchlist = list(val=testdata.b,train=traindata.b),\n",
    "                  print.every_n = 10, early_stopping_rounds = 10, \n",
    "                  maximize = F , eval_metric = \"error\",\n",
    "                  scale_pos_weight = pospredweight,\n",
    "                  alpha=1)\n",
    "  classifiers = c(assign(classifiernames[i],xgb1),classifiers)\n",
    "  \n",
    "  #model prediction\n",
    "  xgbpred <- predict(xgb1,testdata.b)\n",
    "  xgbpred <- ifelse(xgbpred > 0.5,1,0)\n",
    "\n",
    "  cmat = confusionMatrix(factor(xgbpred), factor(testY),positive=\"1\")\n",
    "  \n",
    "  F1 = round(as.numeric(cmat$byClass[7]),3)\n",
    "  accuracy = round(as.numeric(cmat$overall[1]),3)\n",
    "  sensitivity = round(as.numeric(cmat$byClass[1]),3)\n",
    "  specificity = round(as.numeric(cmat$byClass[2]),3)\n",
    "  constrainttype = toString(names(constraint.label.mat[i]))\n",
    "  precision = round(as.numeric(cmat$byClass[3]),3)\n",
    "  \n",
    "  outvec = c(constrainttype, accuracy, sensitivity, specificity,F1,precision)\n",
    "  constraint.performance.table = rbind(outvec, constraint.performance.table)\n",
    "  \n",
    "  # Produce a word importance plot for each category\n",
    "  setwd(\"~/Dropbox/Research/Papers/Delegation-ML-Project/Dataverse Files copy/Pipeline/Importance_Plots_MS/\")\n",
    "  \n",
    "  mat <- xgb.importance(feature_names = colnames(trainX),model = xgb1)\n",
    "  \n",
    "  png(paste(\"term-importance-constraint-ms\",i,\".png\",sep=\"\"))\n",
    "  xgb.plot.importance(importance_matrix = mat[1:10],\n",
    "                      xlab = \"Information Gain\",\n",
    "                      ylab = \"Term\")\n",
    "  dev.off()\n",
    "  \n",
    "  # Plot training and test error\n",
    "  df = data.frame(\n",
    "    Iteration = c(1:length(test.error$test_error_mean), 1:length(test.error$test_error_mean)),\n",
    "    Error = c(test.error$test_error_mean,train.error$train_error_mean), \n",
    "    Type = c(rep(\"Test Error\",length(test.error$test_error_mean)), \n",
    "             rep(\"Train Error\",length(test.error$test_error_mean)))\n",
    "  )\n",
    "  \n",
    "  ggplot(data=df, aes(x=Iteration, y=Error, colour=Type)) +\n",
    "    geom_line()+\n",
    "    geom_point() + theme_classic() +\n",
    "    geom_vline(xintercept=best.iter,linetype=\"dotted\") \n",
    "  ggsave(paste(\"traintest\",i,\".png\",sep=\"\"))\n",
    "  \n",
    "  # Store each trained classifier in the \"Trained-Classifiers\" directory\n",
    "  classifiername = paste(constrainttype,\"_classifier_ms\",\".RData\",sep=\"\")\n",
    "  directory = \"~/Dropbox/Research/Papers/Delegation-ML-Project/Dataverse Files copy/Pipeline/Trained_Classifiers_MS/\"\n",
    "  save.image(\n",
    "    paste(directory,classifiername,sep=\"\")\n",
    "  )\n",
    "  \n",
    "}\n",
    "\n",
    "######## End Loop here######## End Loop here######## End Loop here######## End Loop here######## End Loop here\n",
    "######## End Loop here######## End Loop here######## End Loop here######## End Loop here######## End Loop here\n",
    "######## End Loop here######## End Loop here######## End Loop here######## End Loop here######## End Loop here\n",
    "######## End Loop here######## End Loop here######## End Loop here######## End Loop here######## End Loop here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Member state delegation training and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delegation.MS = data.delegation.MS.new$delegation.member\n",
    "\n",
    "dtm_mat<-as.matrix(dtm.new)\n",
    "mllabel = data.frame(delegation.MS,dtm_mat)\n",
    "train=sample(1:dim(mllabel)[1],\n",
    "             dim(mllabel)[1]*0.95)\n",
    "dtm_mat<-as.matrix(dtm.new)\n",
    "trainX = dtm_mat[train,]\n",
    "testX = dtm_mat[-train,]\n",
    "trainY = delegation.MS[train]\n",
    "testY = delegation.MS[-train]\n",
    "\n",
    "traindata<-data.frame(trainY,trainX)\n",
    "testdata<-data.frame(testY,testX)\n",
    "\n",
    "traindata.b <- xgb.DMatrix(data = trainX,label = trainY) \n",
    "testdata.b  <- xgb.DMatrix(data = testX,label=testY)\n",
    "\n",
    "pospredweight = as.vector(table(trainY)[1])/as.vector(table(trainY)[2])\n",
    "\n",
    "set.seed(100)\n",
    "\n",
    "# Parameter tuning\n",
    "# these are default parameters\n",
    "params <- list(booster = \"gbtree\", objective = \"binary:logistic\", \n",
    "               eta=0.3, gamma=0, max_depth=6, min_child_weight=1, \n",
    "               subsample=1, colsample_bytree=1)\n",
    "\n",
    "xgbcv<- xgb.cv( params = params, data = traindata.b,\n",
    "                nrounds = 500, nfold = 5, showsd = T, \n",
    "                stratified = T, early.stopping.rounds = 20, print.every_n = 10,\n",
    "                maximize = F,\n",
    "                scale_pos_weight = pospredweight)\n",
    "\n",
    "\n",
    "## Plot train and test error\n",
    "test.error = xgbcv$evaluation_log[,4]\n",
    "train.error = xgbcv$evaluation_log[,2]\n",
    "\n",
    "# Which number of iterations has the lowest training error?\n",
    "best.iter = which(xgbcv$evaluation_log$test_error_mean ==  min(xgbcv$evaluation_log$test_error_mean))\n",
    "best.iter = best.iter[1]\n",
    "\n",
    "#first default - model training\n",
    "xgb1 <- xgb.train(params = params, data = traindata.b, \n",
    "                  nrounds = best.iter, \n",
    "                  watchlist = list(val=testdata.b,train=traindata.b),\n",
    "                  print.every_n = 10, early_stopping_rounds = 10, \n",
    "                  maximize = F , eval_metric = \"error\",\n",
    "                  scale_pos_weight = pospredweight,\n",
    "                  alpha=1)\n",
    "\n",
    "#library(DiagrammeR)\n",
    "#gr <- xgb.plot.tree(model=xgb1, trees=0:1, render=FALSE)\n",
    "\n",
    "#model prediction\n",
    "xgbpred <- predict(xgb1,testdata.b)\n",
    "xgbpred <- ifelse(xgbpred > 0.5,1,0)\n",
    "\n",
    "cmat = confusionMatrix(factor(xgbpred), factor(testY),positive=\"1\")\n",
    "\n",
    "accuracy = round(as.numeric(cmat$overall[1]),3)\n",
    "sensitivity = round(as.numeric(cmat$byClass[1]),3)\n",
    "specificity = round(as.numeric(cmat$byClass[2]),3)\n",
    "constrainttype = toString(names(constraint.label.mat[i]))\n",
    "F1 =  round(as.numeric(cmat$byClass[7]),3)\n",
    "precision = round(as.numeric(cmat$byClass[3]),3)\n",
    "\n",
    "outvec = c(\"delegation.ms\", accuracy, sensitivity, specificity,F1,precision)\n",
    "constraint.performance.table = rbind(outvec, constraint.performance.table)\n",
    "\n",
    "# Produce a word importance plot for each category\n",
    "setwd(\"~/Dropbox/Research/Papers/Delegation-ML-Project/Dataverse Files copy/Pipeline/Importance_Plots_MS/\")\n",
    "\n",
    "mat <- xgb.importance(feature_names = colnames(trainX),model = xgb1)\n",
    "\n",
    "png(paste(\"term-importance\",\"-delegation-ms.png\",sep=\"\"))\n",
    "xgb.plot.importance(importance_matrix = mat[1:10],\n",
    "                    xlab = \"Information Gain\",\n",
    "                    ylab = \"Term\")\n",
    "dev.off()\n",
    "\n",
    "# Plot training and test error\n",
    "df = data.frame(\n",
    "  Iteration = c(1:length(test.error$test_error_mean), 1:length(test.error$test_error_mean)),\n",
    "  Error = c(test.error$test_error_mean,train.error$train_error_mean), \n",
    "  Type = c(rep(\"Test Error\",length(test.error$test_error_mean)), \n",
    "           rep(\"Train Error\",length(test.error$test_error_mean)))\n",
    ")\n",
    "\n",
    "ggplot(data=df, aes(x=Iteration, y=Error, colour=Type)) +\n",
    "  geom_line()+\n",
    "  geom_point() + theme_classic() +\n",
    "  geom_vline(xintercept=best.iter,linetype=\"dotted\") \n",
    "ggsave(paste(\"traintest\",\"delegation.png\",sep=\"\"))\n",
    "\n",
    "# Store each trained classifier in the \"Trained-Classifiers\" directory\n",
    "  directory = \"~/Dropbox/Research/Papers/Delegation-ML-Project/Dataverse Files copy/Pipeline/Trained_Classifiers_MS\"\n",
    "  save.image(\n",
    "    paste(directory,\"delegation-ms.RData\",sep=\"\")\n",
    "  )\n",
    "\n",
    "  ######## End Loop here######## End Loop here######## End Loop here######## End Loop here######## End Loop here\n",
    "  ######## End Loop here######## End Loop here######## End Loop here######## End Loop here######## End Loop here\n",
    "  ######## End Loop here######## End Loop here######## End Loop here######## End Loop here######## End Loop here\n",
    "  ######## End Loop here######## End Loop here######## End Loop here######## End Loop here######## End Loop here\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
